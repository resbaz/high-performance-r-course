{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 2: Optimization\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Unkind people have spread rumours that Python is terribly slow. But that's not true. Pure Python trades convenience for performance, but we can always adjust the dial back -- do a little more work, and we can get excellent performance.\n",
    "\n",
    "The trick is focusing this effort. Not eveything in your code needs to go fast. Hopefully you've now figured out where things are too slow, and we can now focus on optimising just those bits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Q: Why can Python be slow?\n",
    "\n",
    "A: It's an interpreted language with dynamic typing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 0 \n",
    "\n",
    "# Python doesn't compile, so can't optimise below \n",
    "# (we should be able to precalculate answer)\n",
    "for i in range(100): \n",
    "    a += i # <- Will check types for 'a' and 'i' every time they are used (100 times)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Python can be slow because it doesn't make you define variable types (i.e. whether they are strings, integers, etc.). This is convenient, but means Python has to check the type of every variable each time it gets used.\n",
    "\n",
    "Python is also an interpreted language, similar to R and Javascript, but unlike C++ or Java. That means the code doesn't get compiled before it runs (only simplified to byte code). Again, that's convenient (no waiting, and we can do things interactively), but means there's no compiler to try and optimise your code for you automatically, and there's an intermediate layer to interpret your code which slows things down a little.\n",
    "\n",
    "But Python is 'batteries included' -- there are plenty of mature third-party packages that can reverse one or both of these characteristics for the bits of your code that need it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Options\n",
    "\n",
    "* Restructurting your code\n",
    "* NumPy - Work with arrays/matrices\n",
    "* Pandas - Builds on NumPy for conveniently working with tables\n",
    "* Cython - Converts bits of your code to low-level C code (which can be compiled)\n",
    "* Numba & PyPy - Automatically compiles your code on the fly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Pure Python\n",
    "from random import random\n",
    "\n",
    "a = [random() for _ in range(100000)]\n",
    "b = [random() for _ in range(100000)]\n",
    "\n",
    "%timeit c = [x * y for x, y in zip(a, b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NumPy\n",
    "import numpy as np\n",
    "\n",
    "a = np.array(a)\n",
    "b = np.array(b)\n",
    "\n",
    "%timeit c = a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This should give about 40ms vs 40us -- that is NumPy is about 100x faster here!\n",
    "\n",
    "Numpy includes a bunch of functions for working with arrays and matrics, including things like finding min/max, averages, and so on. \n",
    "\n",
    "If you're working with large sets of numbers, for instance doing linear algebra, then you should use NumPy rather than built-in Python types. This works a bit like MATLAB. You get to work with arrays and matrices, and there are many operations built-in, and they are all optimised to run fast. There are even more operations in the sister package SciPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "raw_data = {'first_name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n",
    "        'last_name': ['Miller', 'Jacobson', \"Faye\", 'Milner', 'Cooze'], \n",
    "        'age': [42, 52, 36, 24, 73], \n",
    "        'testScore': [25, 94, 57, 62, 72]}\n",
    "df = pd.DataFrame(raw_data, columns = ['first_name', 'last_name', 'age', 'testScore'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# A very small taste of what Pandas can do...\n",
    "\n",
    "# Query\n",
    "df[df['age'] > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do Math\n",
    "df['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import/export\n",
    "df.to_csv('output.csv')\n",
    "\n",
    "# Plot\n",
    "df.plot.scatter('age', 'testScore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "I've just given a little taste here.\n",
    "\n",
    "Pandas is a fantastic package for dealing with tabular data, think of it as a step up from NumPy (though it still uses NumPy under the covers). For example, a time-series of data points, or maybe a summary of results. \n",
    "\n",
    "It's fast, but also saves you from writing a heap of code. If nothing else, this is certainly a Python package you should learn... and we run dedicated training on it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Baseline -- Pure Python\n",
    "def primes(kmax):\n",
    "    result = []\n",
    "    p = [None] * 1000\n",
    "    if kmax > 1000:\n",
    "        kmax = 1000\n",
    "    k = 0\n",
    "    n = 2\n",
    "    while k < kmax:\n",
    "        i = 0\n",
    "        while i < k and n % p[i] != 0:\n",
    "            i = i + 1\n",
    "        if i == k:\n",
    "            p[k] = n\n",
    "            k = k + 1\n",
    "            result.append(n)\n",
    "        n = n + 1\n",
    "    return result\n",
    "\n",
    "%timeit out = primes(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile cython_example.pyx\n",
    "\n",
    "def primes(int kmax):\n",
    "    cdef int n, k, i   # Let Cython know these are always 32 bit integers.\n",
    "    cdef int p[1000]   # ...and to allocate an array of max length 1000.\n",
    "    result = []\n",
    "    if kmax > 1000:\n",
    "        kmax = 1000\n",
    "    k = 0\n",
    "    n = 2\n",
    "    while k < kmax:\n",
    "        i = 0\n",
    "        while i < k and n % p[i] != 0:\n",
    "            i = i + 1\n",
    "        if i == k:\n",
    "            p[k] = n\n",
    "            k = k + 1\n",
    "            result.append(n)\n",
    "        n = n + 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile setup.py\n",
    "\n",
    "from distutils.core import setup\n",
    "from Cython.Build import cythonize\n",
    "\n",
    "setup(\n",
    "    ext_modules = cythonize(\"cython_example.pyx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python setup.py build_ext --inplace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import cython_example\n",
    "# dir(cython_example)\n",
    "%timeit out = cython_example.primes(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Cython lets you provide 'hints' so that it can figure out the types of your variables, and so convert it to C which can be compiled before it runs. Often this is really easy! \n",
    "\n",
    "Downside is you'll need to setup a C compiler (though you may already have one), and compile your code in advance.\n",
    "\n",
    "In the case of this example, those couple little tweaks sped things up by ~40x!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "\n",
    "@numba.jit\n",
    "def primes(kmax):\n",
    "    result = []\n",
    "    p = [None] * 1000\n",
    "    if kmax > 1000:\n",
    "        kmax = 1000\n",
    "    k = 0\n",
    "    n = 2\n",
    "    while k < kmax:\n",
    "        i = 0\n",
    "        while i < k and n % p[i] != 0:\n",
    "            i = i + 1\n",
    "        if i == k:\n",
    "            p[k] = n\n",
    "            k = k + 1\n",
    "            result.append(n)\n",
    "        n = n + 1\n",
    "    return np.array(result)\n",
    "\n",
    "%timeit out = primes(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "With Numba, if you're lucky, you can just pop '@jit' at the top of your function and it will go fast! But in this case, it doesn't seem any faster!?\n",
    "\n",
    "In the background, Numba tries to compile this code just before executing (unlike cython, where you do this in advance), and infer the types based on how you use it. If Numba can't figure out how to do this, it will just stick to using normal Python and your code will still work, but won't be compiled to speed it up.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "\n",
    "@numba.jit(nopython=True) # The 'nopython' part forces things to be compiled.\n",
    "def primes(kmax):\n",
    "    result = []\n",
    "    p = [None] * 1000\n",
    "    if kmax > 1000:\n",
    "        kmax = 1000\n",
    "    k = 0\n",
    "    n = 2\n",
    "    while k < kmax:\n",
    "        i = 0\n",
    "        while i < k and n % p[i] != 0:\n",
    "            i = i + 1\n",
    "        if i == k:\n",
    "            p[k] = n\n",
    "            k = k + 1\n",
    "            result.append(n)\n",
    "        n = n + 1\n",
    "    return np.array(result)\n",
    "\n",
    "%timeit out = primes(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "If, however, you use `nopython=True`, Numba will insist that everything be compilable, and raise an error if it gets stuck. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def primes(kmax):\n",
    "    result = []\n",
    "    p = [np.nan] * 1000   # Use NumPy NaN instead of Pure Python 'None' so Numba can understand.\n",
    "    if kmax > 1000:\n",
    "        kmax = 1000\n",
    "    k = 0\n",
    "    n = 2\n",
    "    while k < kmax:\n",
    "        i = 0\n",
    "        while i < k and n % p[i] != 0:\n",
    "            i = i + 1\n",
    "        if i == k:\n",
    "            p[k] = n\n",
    "            k = k + 1\n",
    "            result.append(n)\n",
    "        n = n + 1\n",
    "    return np.array(result)\n",
    "\n",
    "%timeit out = primes(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Only some Python constructs can be compiled and so you might need to make a few tweaks to your code, or provide hints on the signature of your function (that is, the datatype of its inputs and outputs).\n",
    "\n",
    "In this case, the error message suggested that it didn't like our array of 'None'. Numba generally works seamlessly with NumPy, so let's create a list of Numpy NaN objects instead.\n",
    "\n",
    "This now works, and executes about as fast as our Cython example, except Numba has figured out the datatypes for itelf.\n",
    "\n",
    "Again, I'm just scratching the surface of Numba, this is again a very rich package for doing high performance work with Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Don't overdo it...\n",
    "\n",
    "<blockquote>We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil. ~Donald Knuth</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"efficiency.png\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "At this point, you've probably gathered that you could spend alot of time tweaking things, potentially more than you'll save!\n",
    "\n",
    "Try not to go overboard. Your code doesn't need to be perfect, and indeed optimising everything can just make it difficult to understand and debug. You can always consider saving your time and using a bigger computer instead, which we'll talk about in the next part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Challenges!\n",
    "\n",
    "Go here: http://go.unimelb.edu.au/dgh6\n",
    "\n",
    "Select optimization challenge (1 to 3), and click 'Clone' to start your own instance.\n",
    "\n",
    "You can login using your University email, or create a (free) Microsoft account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Challenge 1**\n",
    "* The second approach is faster because we are allocating all the memory we need in one step, rather than having to create a new (slightly bigger) one over and over again.\n",
    "* ...so try to allocate all the space you need for your computations in one go (you can always use NaN to mark empty data points)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Challenge 2**\n",
    "* Using the built-in NumPy methods is vastly quicker than doing it yourself! \n",
    "* This is because there are many low-level highly-optimised libraries available for doing these sorts of calculations, which NumPy gives you an interface to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Challenge 3**\n",
    "* Can use:  ```data[data['age'] < 30]['name'].values```\n",
    "* For this (very small) dataset, it isn't any faster. But for bigger datasets it certainly is. \n",
    "* It's more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
